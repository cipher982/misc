üöÄ Transformer Backend Performance Report
============================================================

üìä Performance Summary
----------------------------------------
Model           Backend  Forward      Memory     Speedup  Efficiency
---------------------------------------------------------------------------
16d_1l_2h       numpy    0.70         0.6        1.00    x 1.077     
                python   20.33        0.4        0.03    x 49.291    
                torch    1.11         34.7       0.63    x 0.032     

32d_2l_4h       numpy    1.11         0.8        1.00    x 1.417     
                torch    1.53         0.1        0.72    x 14.298    

64d_4l_8h       numpy    2.03         4.5        1.00    x 0.453     
                torch    2.76         0.2        0.73    x 13.995    


üîç Detailed Analysis
----------------------------------------

üìà 16d_1l_2h:
   Fastest: numpy
   numpy:
     ‚Ä¢ Forward time: 0.70ms
     ‚Ä¢ Memory usage: 0.6MB
     ‚Ä¢ Parameters: 2,884
     ‚Ä¢ Loss: 3.0122
     ‚Ä¢ Speedup: 1.00x
   python:
     ‚Ä¢ Forward time: 20.33ms
     ‚Ä¢ Memory usage: 0.4MB
     ‚Ä¢ Parameters: 2,916
     ‚Ä¢ Loss: 2.9852
     ‚Ä¢ Speedup: 0.03x
   torch:
     ‚Ä¢ Forward time: 1.11ms
     ‚Ä¢ Memory usage: 34.7MB
     ‚Ä¢ Parameters: 2,916
     ‚Ä¢ Loss: 2.9810
     ‚Ä¢ Speedup: 0.63x

üìà 32d_2l_4h:
   Fastest: numpy
   numpy:
     ‚Ä¢ Forward time: 1.11ms
     ‚Ä¢ Memory usage: 0.8MB
     ‚Ä¢ Parameters: 20,338
     ‚Ä¢ Loss: 3.9385
     ‚Ä¢ Speedup: 1.00x
   torch:
     ‚Ä¢ Forward time: 1.53ms
     ‚Ä¢ Memory usage: 0.1MB
     ‚Ä¢ Parameters: 20,402
     ‚Ä¢ Loss: 3.8951
     ‚Ä¢ Speedup: 0.72x

üìà 64d_4l_8h:
   Fastest: numpy
   numpy:
     ‚Ä¢ Forward time: 2.03ms
     ‚Ä¢ Memory usage: 4.5MB
     ‚Ä¢ Parameters: 146,788
     ‚Ä¢ Loss: 4.6038
     ‚Ä¢ Speedup: 1.00x
   torch:
     ‚Ä¢ Forward time: 2.76ms
     ‚Ä¢ Memory usage: 0.2MB
     ‚Ä¢ Parameters: 146,916
     ‚Ä¢ Loss: 4.6211
     ‚Ä¢ Speedup: 0.73x